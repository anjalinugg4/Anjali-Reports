| Date   | Notes
| :----- | :-------------------------------
|6/5| electronics project, read research publications, experimented with Prof Clark's datasets in jupyter notebook
|6/6 | zoomed with RAs about UE vs. TM, experimented with TM, worked with fastai, watched UE robotics tutorials
|6/7 | continued working with Twinmotion and fastai, watched Open Stage Control tutorials
|6/8 | built a new model using fastai tutorial that could distinguish between makeup products, followed Daisy's example in building a confusion matrix, continued Twinmotion work
|6/9 | continued fastai video tutorials, UE robotics tutorials and followed along with the step-by-steps

# Activities

- jupyter notebook with Prof Clark's dataset

![Jupyter Notebook](/assets/2023-06-12/jupy.png)

- followed the fastai lesson to build a model that can distinguish between images of mascara and lipstick products

![Jupyter Notebook](/assets/2023-06-12/mascara1.png)
![Jupyter Notebook](/assets/2023-06-12/mascara2.png)

- building a Twinmotion project

![Twinmotion Project](/assets/2023-06-12/twinmotionproj.png)

![Twinmotion Project](/assets/2023-06-12/newtwin.png)

-setting up virtual robots in UE through following along with the video tutorials on the doc

# Issues

- navigating Twinmotion and getting used to the application
- building my own models using both Prof Clark's dataset/code and fastai's guide
- finding a way to merge the benefits of Twinmotion and UE- TM is easier in building models and adding assets, but UE has more complex features that we'd want to implement


# Plans

- data collection
- getting more practice with OSC
- continuing to build and train virtual robots within UE

# Article Summaries

- research papers discussed the methodology of past models and what resulted in the best accuracy. I found the idea of storing the previous output of the model to be really interesting, as it allows the model to use past decisions to influence its further actions. I was a bit confused on the distinction between the hybrid models vs. stacked and panel input, and Christi's response was super helpful:

- "Yes, they all provide information about past state, as do the ConvLSTM models. The difference is how they do it. Hybrid model takes past state as the most immediate previous categorical input (a number corresponding to left, right, forward) and couples that with a present image. Stacked models literally stack two images on top of each other, a previous image and a present image. Paneled models do the same thing except they place the two images side-by-side on a horizontal plane like a panel. We pick strategies by testing them all out and seeing which one works best. Yes, they all provide information about past state, as do the ConvLSTM models. The difference is how they do it. Hybrid model takes past state as the most immediate previous categorical input (a number corresponding to left, right, forward) and couples that with a present image. Stacked models literally stack two images on top of each other, a previous image and a present image. Paneled models do the same thing except they place the two images side-by-side on a horizontal plane like a panel. We pick strategies by testing them all out and seeing which one works best."