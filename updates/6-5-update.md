| Date   | Notes
| :----- | :-------------------------------
|5/30| Attended Harvey Mudd talk on computer vision, watched Lecture 1 of fastai, began my own creation of Oldenborg using UE
|5/31 | created gitea instance account, continued UE work, began Video 2 in fastai course
|6/1 | attended group meeting, installed Live Share extension, continued UE work, reviewed gitea
|6/2 | Zoomed with research team about how to use UE, walked them through my model, discussed project goals/future tasks

# Activities

- explored UE, created my own Oldenborg model using Polycam Capture and Desmos visualization 
![Desmos visualization](/assets/6-5-ss/desmos.png)

![Polycam visualization](/assets/6-5-ss/polycam.png)

![UE Oldenborg](/assets/6-5-ss/UEmodel.png)



# Issues

- navigating UE and learning how to use it (exploring dimensions, perspectives, lighting, etc.)

# Plans

- data collection
- further finetuning of Oldenborg model
- get familiar with Twinmotion

# Article Summaries

- fastai tutorials are super helpful!
- Summary of HMC talk: discussed the intersection of vision and machine learning. Exposes us to how complicated (but also limited) human vision is! Understanding other animals' visual techniques can help us develop even more complex models (ex: otters' whiskers!) Further thought - what if we extended this discussion to the other senses (ie. hearing, scent). What are the benefits/implications of gaining more insight into this?