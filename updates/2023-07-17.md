| Date   | Notes
| :----- | :-------------------------------
|7/10 | completed with MLOps course, read and took notes on iGibson paper in preperation for Thursday's discussion, took notes on how to clean up UE blueprints, worked on the to do list with the boxnav code (added documentation/type hints, worked on fixing boxes, changed the --collect arg to save screenshots to user-chosen folder)
|7/11 | re-read through research writeup, discussed iGibson paper with Francisco, revisted Oldenborg model with Blender, worked on "dying gracefully" and getting rid of method call redundancy in boxnav code, worked on adjusting the coordinates of the boxsim code to be to scale of the Oldy model in Unreal Engine
|7/12 | 
|7/13 | 

# Activities

- 
![photo name](/assets/2023-07-17/photo.png)


# Issues
- figuring out how to mitigate the issue of duplicating the function calls in the wrapper in boxunreal

Example:
```
    def num_actions_taken(self) -> int:
        """Returns how many actions the agent has taken towards its final target."""
        return self.navigator.num_actions_taken()
```
- re-working the box dimensions in the animation to be to scale of the Oldenborg model

# Plans

- 

# Article Summaries

- Research Paper Notes for 7/6 Meeting:
    - iGibson 2.0 creates an open-source kinodynamic (accounts for physics and kinematic constraints) simulation environment that supports simulation of diverse set of household tasks
    - 3 innovations: supports object states (temp/wetness/cleanliness levels), predicate logic functions that map to logic states (ie. Cooked/Soaked), includes VR to put humans in its scenes to "collect demonstrations" -> use for imitation learning
    - env goes beyond only kinodynamics (pose,motion,forces) and extends to functional states(wetess, cleanliness, etc) -> "extended physical states"
    - by classifying the continuous physical states into logic states based on specific criteria, it allows for more meaningful rep of system's behavior
    - implements generative functions: samples valid simulated physical state based on logical states -> logical states are inputs to the generative functions that created physical states that align with the logical states
    - presents the following contributions: set of new physical properties and logical predicates, set of generative functions associated with logical preds, rule-based mechanism exploiting these functions to created a realistic scene, novel VR interface that allows humans to collect demonstrations for robot learning
    - goes beyond only maintainin a symbolic state like raw/cooked; also provides simulation of the physical process that leads to this state (ex: heat transfer) -> leads to more complex activites/realistic executions
    - object centered representation: simulator maintains a single value for each state for every object (rigid, flexible, articulated -> mechanical system with interconnected components)
    - latent properties: agents are not able to observe them directly
    - every obj in env is in WorldNet so we can annotate what extended states every object needs
    - must bridge the gap between extended states (temp) and natural description of activity (cooking fish); define functions that map the extended states to the logical states
    - generative system simplifies the issue of creatin ga highly populated simulated house; semantic rules (how things are related to each other) define the probability for objects in specific rooms
    - in VR interface, humans are an avatar that can control hands and head -> train imitation learning policy for bimanual task (task that involves both hands)
    - evaluate capabilities of env, created novel tasks for AI agent: grasping book, soaking towel, cleaning stained shelf, cooking meat, slicing fruit, bimanual pick up/place
    - Summary: Within this paper, the research team created a iGibson 2.0 environment that supported the kinodynamic simulation of a diverse set of household tasks. The object-centric representation is unique in that it supports extended object states (ie. cleanlines and temperature), uses logical predicates to map simulation states to logical states, possesses a generative mechanism that creates simulated worlds based on logical descriptions, and collects human demonstrations for imitation learning through a VR interface. The environment goes beyond maintaining a symbolic state (ie. raw or cooked), and also provides a simulation of the physical process that leads to this state, thus leading to more complex activites and realistic executions. The iGibson environment finds solutions to more complex tasks that cannot be solved by previously developed simulation environments for robotics, and can expand the possibilities of AI problem-solving to household activites. 


    - How does this paper relate to our labâ€™s work?
        - also creates a simulation environment for robots within AI research
        - creates a process that allows the robot to navigate the environment
        - also deals with manipulating states in order to maximize the robot's accuracy in making decisions 
    - What techniques should we apply to our work?
        - robot being able to interact with various objects
        - being able to alter functional states along with texture/resolution/materials (adding water spots on terrain, dirt patches,creating slices in the floorplan to navigate over; creating a more real-world realistic environment) -> does Unreal Engine have these capabilities in its blueprint?
        - implementing virtual reality within our environment to utilize a imitation learning strategy (especially in terms of a wandering path)

    - What could the authors have done better?
        - when describing the accuracy regarding the 6 novel tasks, the performance rate could've been depicted clearer; perhaps in a diagram rather than just including it within the paragraph itself
        - doesn't address limitations of work or how it can be actually be implemented in the real world
        - also doesn't address cost of creating such an environment; is this something that's readily available to households or is it too complex/expensive to really be implemented yet?
- Notes on "15 Tips for Clean and Tidy Blueprints in Unreal Engine"
    - reroute nodes allow you to change the flow of your lines so they are visible
    - sequence nodes will execute branches even if one node fails
    - switch on enum can implement a different functionality for each branch
    - straighten your nodes and connections where they align properly 
    - keep your node layout consistent 
    - make many helper functions
    - create local variables
    - collapses nodes (be cautious about executing outputs after the collapse nodes)
    - set timer by function name node allows you to call functions after a delay
    - select node allows you to change single value based on enum/boolean
    - use comments to help break up nodes visually and categorize them
    - use custom events to create functions on event graph
    - bp function libraries are good for functionalities you don't want to be tied to a specific object
    - plugins make organizing blueprints easier

    